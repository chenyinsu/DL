# Enabling ISP-less Low-Power Computer Vision： 核心算法流程解析

## 一、 研究动机与核心问题

在传统的计算机视觉（CV）系统中，图像传感器捕获的高分辨率**原始RAW数据（Bayer格式）** 必须经过一个复杂的**图像信号处理器（ISP）**  pipeline，才能转换为视觉上悦目且适合深度学习模型处理的**sRGB图像**。然而，ISP单元计算量大、能耗高，在资源受限的边缘设备（如智能手机、IoT摄像头）上部署面临巨大挑战。


**核心矛盾**：
1.  **训练与推理的域差异（Covariance Shift）**：绝大多数大型CV数据集（如COCO、ImageNet）由ISP处理后的sRGB图像组成。然而，**直接在传感器端捕获的RAW图像**其像素强度分布、颜色模式与sRGB图像存在巨大差异。若直接将在一个域（sRGB）上训练的模型，部署到另一个域（RAW）进行推理，会导致严重的**性能下降**（论文中指出精度下降可达~8.6%）。
2.  **边缘设备的资源瓶颈**：ISP pipeline本身以及将高分辨率RAW数据从传感器传输到处理单元（如CPU/GPU）的过程，会消耗巨大的**带宽和能量**，这与边缘设备对低功耗、高效率的要求背道而驰。
3.  **缺乏大规模RAW数据集**：难以获取大规模、标注好的RAW图像数据集来从头训练模型，因为RAW数据通常只在相机内部处理，很少被保存和公开。

**因此，本研究的核心动机是**：**彻底绕过（Bypass）ISP**，构建一个**直接从RAW数据进行推理的低功耗计算机视觉系统**。为此，需要解决两个关键问题：(1) 如何获得大量用于训练模型的RAW数据？(2) 如何在不使用复杂ISP的情况下，对RAW数据进行有效处理以保持甚至提升模型精度？

## 二、 核心思想与总体框架

论文提出了一个软硬件协同设计的整体框架，其核心思想是通过**反转ISP流程**来生成大规模RAW训练数据，并设计**轻量级的像素内（In-Pixel）处理**来替代部分ISP功能，最终实现高性能、低功耗的ISP-less CV系统。


该框架包含三个核心创新点：
1.  **ISP反转（ISP Inversion）**：使用可逆神经网络将现有的sRGB数据集（如COCO）“反向”处理，生成其对应的RAW版本，从而创建大规模RAW训练数据集。
2.  **像素内去马赛克（In-Pixel Demosaicing）**：提出一种模拟计算方案，在传感器像素阵列内部实现极其轻量级的去马赛克操作，为模型提供更丰富的颜色信息。
3.  **小样本学习（Few-Shot Learning）**：利用生成的大规模模拟RAW数据集作为基类（Base Classes），结合极少量真实捕获的RAW数据（新类，Novel Classes），通过小样本学习技术进一步提升模型在真实RAW数据上的性能。

## 三、 核心算法流程

### 1. ISP管道反转（ISP Inversion）

**目标**：将大规模sRGB数据集（如COCO）转换为对应的RAW Bayer格式数据集，用于训练CV模型。

**方法**：采用基于**流模型（Flow-based Model）** 的可逆神经网络（Invertible Neural Network, INN）。该模型由一系列可逆的双射函数（Bijective Function）组成，能够无损地在sRGB域和RAW域之间进行转换。

*   **核心组件 - 仿射耦合层（Affine Coupling Layer）**：
    给定一个D维输入 `m`，将其分为两部分 `m_{1:d}` 和 `m_{d+1:D}`，输出 `n` 的计算如下：
    `n_{1:d} = m_{1:d} + r(m_{d+1:D})`
    `n_{d+1:D} = m_{d+1:D} ⊙ exp(s(m_{1:d})) + t(m_{1:d})`
    其中 `s` 和 `t` 是由神经网络实现的缩放和平移函数，`r` 是任意函数，`⊙` 是哈达玛积（逐元素乘）。其逆变换同样可导，允许从输出 `n` 精确地恢复输入 `m`。

*   **训练与推理**：
    1.  **训练**：使用MIT-Adobe 5K等包含（RAW, sRGB）图像对的摄影数据集，训练INN模型学习从RAW到sRGB的映射 `f`。
    2.  **反转**：训练完成后，使用该模型的**逆变换** `f^{-1}`，处理sRGB数据集（如COCO）中的每一张图片，生成其对应的RAW版本。
    3.  **马赛克处理（Mosaicing）**：将INN输出的“去马赛克”后的RAW图像，通过选择Bayer模式中对应位置的R、G、B值，重新处理成**马赛克格式的RAW图像**，模拟相机传感器最原始的输出。

**结果**：成功创建并发布了**RAW-COCO**数据集，这是第一个大规模、用于高级视觉任务（如目标检测）的RAW图像基准数据集。

### 2. 像素内去马赛克（In-Pixel Demosaicing）

**目标**：在几乎不增加功耗和延迟的前提下，为RAW图像提供更丰富的颜色信息，以提升模型性能。

**观察**：完全未经处理的马赛克RAW图像（每个像素只有一个颜色通道的值）信息缺失严重。但传统的数字去马赛克算法复杂，不适合在资源受限的传感器端进行。

**方案**：提出一种**模拟域、低开销的去马赛克方案**，可直接在像素阵列中实现。

*   **操作**：对于一个2x2的RGGB Bayer patch：
    *   **R和B通道**：直接保留各自位置的一个像素值。
    *   **G通道**：将两个G像素的**模拟值进行加和**（在模拟域实现），然后在数字域通过一次右移操作（除以2）来实现平均。
    *   最终得到一个3通道的“去马赛克”图像，但其空间分辨率降为原来的1/4（每个2x2 patch变为1个像素）。

*   **硬件实现**：
    通过在像素阵列中设计**两套交错的行选通线（Row-Select, Green-Select）** 和**列线开关（Column-Switch）**，分两个周期完成操作：
    1.  **周期1**：激活`Row-Select`线，读取R和B像素的值。
    2.  **周期2**：激活`Green-Select`线并闭合`Column-Switch`，将两个G像素的模拟电流/电压在列线上加和，然后由ADC读取。


    该方案**无需额外的数字计算单元**，也**不降低帧率**，仅在模拟读取阶段完成操作，极度高效。

### 3. 小样本学习（Few-Shot Learning）

**目标**：解决真实RAW数据集（如PASCALRAW）规模小、标注少的问题，提升模型在真实数据上的性能。

**挑战**：真实RAW数据与生成的模拟RAW数据之间存在分布差异（Domain Gap）。

**方案**：采用**基于微调（Fine-tune）的小样本学习方法**（TFA: Two-stage Fine-tuning Approach）。
1.  **基数据集（Base Dataset）**：使用生成的、大规模的模拟RAW数据集（如RAW-COCO）预训练模型。
2.  **新数据集（Novel Dataset）**：使用极少量（如每类30个样本）的真实RAW数据（如PASCALRAW）。
3.  **两阶段训练**：
    *   **阶段一**：在基数据集上正常训练模型。
    *   **阶段二**：仅使用新数据集的数据，对模型的**检测头（Classification and Regression Heads）** 进行微调，而保持**特征提取主干（Backbone）** 的权重固定。这种“冻结主干、微调头部”的策略能有效防止在小数据集上过拟合。

**结果**：此方法能显著提升模型在真实小规模RAW数据集上的性能（mAP提升高达20.5%）。

## 四、 实验验证与性能分析

论文在多个数据集和模型上进行了充分的实验验证：

### 1. 视觉唤醒词（VWW）数据集（分类任务）
*   **模型**：轻量级MobileNetV2-0.35x
*   **结果**：
    *   直接在RAW马赛克图像上训练和推理，准确率为87.47%。
    *   使用提出的**像素内去马赛克**后，准确率提升至**89.92%**，甚至比在sRGB图像上推理（89.29%）的精度更高。
    *   这证明了即使在分类任务中，简单的颜色信息增强也能带来收益。


### 2. COCO数据集（检测任务）
*   **模型**：Faster R-CNN (ResNet-101) 和 YOLOv3
*   **结果**：
    *   在生成的RAW-COCO数据集上训练，在RAW数据上测试，mAP达到42.8%，显著优于直接拿sRGB预训练模型去测试RAW数据的基线（33.8%）。
    *   使用像素内去马赛克版本的数据，mAP为37.8%。虽然分辨率下降导致mAP低于全分辨率RAW训练，但依然远高于基线。


### 3. PASCALRAW数据集（真实RAW数据检测）
*   **结果**：
    *   直接使用sRGB预训练模型在真实RAW数据上测试，性能极差（mAP仅2.7%）。
    *   使用生成的RAW-COCO作为基数据集进行预训练，再在PASCALRAW上微调，mAP大幅提升至13.4%。
    *   进一步结合**小样本学习**，mAP可进一步提升至**20.8%**（YOLOv3）和**29.8%**（Faster R-CNN），证明了整套方案的有效性。


### 4. 能效与带宽收益
提出的ISP-less方案带来了显著的节能和带宽优化：
*   **带宽**：像素内去马赛克方案可减少**75%** 的数据传输量。
*   **能量**：整体系统能量显著降低，尤其适合tinyML等超低功耗场景。


## 五、 总结与贡献

本研究系统地提出并验证了一整套实现**无ISP低功耗计算机视觉**的方案，其核心贡献在于：

1.  **数据层面**：首创性地利用**可逆神经网络反转ISP流程**，构建了大规模RAW图像数据集（RAW-COCO），解决了RAW数据匮乏的根本问题。
2.  **算法层面**：提出了**极轻量的像素内去马赛克**算法，在模拟域完成处理，以可忽略的 overhead 为模型提供了更有效的颜色信息输入。
3.  **优化层面**：引入了**小样本学习**技术，弥合了模拟RAW与真实RAW之间的域差异，显著提升了模型在真实场景下的性能。
4.  **系统层面**：通过软硬件协同设计，证明了ISP-less CV系统在**大幅降低带宽和能耗**的同时，能够**实现更高或可比的精度**，为视觉任务在边缘设备的部署提供了新的可行路径。

这项工作为未来真正意义上的“感算一体”（In-Sensor Computing）和超低功耗智能视觉系统奠定了坚实的基础。
